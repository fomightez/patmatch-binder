{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatMatch Use With a Genome and Protein Sequences + Python\n",
    "\n",
    "Here I'll demonstrate use of the stand-alone, command line based PatMatch on genomic nucleotide sequences and protein sequences. \n",
    "Hopefully, you'll see the the script you used previously to move to Python will work for such data cases as well.\n",
    "\n",
    "### Preparing to use PatMatch software on genomic and protein sequence data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Genome file*\n",
    "\n",
    "As far as the genome, normally I'd recommnend obtaining the *Saccharomyces cerevisiae* budding yeast from [Illumina’s iGenomes site](https://support.illumina.com/sequencing/sequencing_software/igenome.html), and in fact, I have written out the commands necessary on the standard command line [here](http://fenglabwkshopmay2015.readthedocs.io/en/latest/genome%20of%20interest%20data%20acquisition/). [Illumina’s iGenomes site](https://support.illumina.com/sequencing/sequencing_software/igenome.html) is a collection of reference sequences and annotation files for commonly analyzed organisms.  However, it seems FTP-based and FTP sources won't work via Binder, and instead the genome file has been included already as `Sc_genome.fa`. (This has the advantage that it spares users from waiting a few seconds for the download to process.)\n",
    "\n",
    "Alternatively, the following code pasted in a Jupyter notebook cell will work in Jupyter environments run via Binder to get the genome sequnce from [here](https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/). However, the genome file, `S288C_reference_sequence_R64-2-1_20150113.fsa`, from this source doesn't seem to contain nicely labeled chromosomes on the FASTA description lines and instead has cryptic alphanumerical code identifiers.\n",
    "\n",
    "```\n",
    "!curl -O https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/S288C_reference_genome_Current_Release.tgz\n",
    "!tar -xzf S288C_reference_genome_Current_Release.tgz\n",
    "!cp S288C_reference_genome_R64-2-1_20150113/S288C_reference_sequence_R64-2-1_20150113.fsa .\n",
    "!rm -rf S288C_reference_genome_R64-2-1_20150113\n",
    "!rm S288C_reference_genome_Current_Release.tgz\n",
    "```\n",
    "\n",
    "Given those cryptic labels, we'll stick with the included FASTA genome file.\n",
    "\n",
    "*Protein sequences*\n",
    "\n",
    "Following advice from [here](https://www.biostars.org/p/106065/#106110) is it is easy to select several and get quite a few at once from [here](http://www.uniprot.org/uniprot/?query=%28taxonomy%3A9606%29+AND+reviewed%3Ayes) because it formats a link when choose 'download' and designate 'uncompressed'. That link obtained can be used to make a `curl` command to get the text.  \n",
    "Running the next cell will get a file of several human protein sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \"https://www.uniprot.org/uniprot/?sort=&desc=&compress=no&query=id:P62258%20OR%20id:P61981%20OR%20id:P31947%20OR%20id:P63104%20OR%20id:P30443%20OR%20id:Q16537%20OR%20id:Q30167%20OR%20id:Q95IE3%20OR%20id:Q5Y7A7%20OR%20id:P46952%20OR%20id:P31937%20OR%20id:P30542%20OR%20id:Q9NS82%20OR%20id:Q9NRG9%20OR%20id:Q2M2I8%20OR%20id:O43741%20OR%20id:P54619%20OR%20id:Q9UNQ0%20OR%20id:Q9H172%20OR%20id:Q9H222%20OR%20id:Q8N2K0%20OR%20id:Q96I13%20OR%20id:Q8IZP0%20OR%20id:P49748%20OR%20d:Q5HYA8%20OR%20id:Q9UHC1%20OR%20id:Q9UHV7%20OR%20id:P52732%20OR%20id:Q15058%20OR%20id:Q9P2E2%20OR%20id:Q9P2G9%20OR%20id:Q86Z14%20OR%20id:Q8NB78%20OR%20id:Q9Y4C1&format=fasta\" > human_examples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that download fails, paste `!cp human_examples_bckup.txt human_examples.txt` into a cell and run it so that the later steps will still work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PatMatch on Genomic Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need the script you used prior to convert the results to a dataframe. To insure that is already here, you can run this next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://raw.githubusercontent.com/fomightez/sequencework/master/patmatch-utilities/patmatch_results_to_df.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running PatMatch on Protein Sequences\n",
    "\n",
    "Prepare the FASTA file obtained per usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../patmatch_1.2/unjustify_fasta.pl human_examples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `PatMatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../patmatch_1.2/patmatch.pl -p \"STEP\" human_examples.txt.prepared 1 s > human_protein.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring the results into Python. Since we brought the script into where this notebook is running earlier, we can run the Python script already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run patmatch_results_to_df.py human_protein.out --pattern STEP -name our_motif --protein_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"patmatch_pickled_df.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cover somewhere\n",
    "\n",
    "* Other ways to add the data to the running Binder are available using the file directory dashboard. EXPLAIN HOW TO UPLOAD using JUPYTER GUI.\n",
    "\n",
    "\n",
    "* using `protein_results` flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://gist.githubusercontent.com/fomightez/b012e51ebef6ec58c1515df3ee0c850a/raw/300da6c67ceeaf5384a3e500648b993345c361cb/run_every_eight_mins.py\n",
    "import time\n",
    "\n",
    "def executeSomething():\n",
    "    #code here\n",
    "    print ('.')\n",
    "    time.sleep(480) #60 seconds times 8 minutes\n",
    "\n",
    "while True:\n",
    "    executeSomething()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#999\">(Alternative ways to import data using the Jupyter environment's graphical user interface will be covered below.)</font>\n",
    "\n",
    "Check the file listing by executing the next cell to see the FASTA-formatted file has been retrieved. Work through the following cells simialrly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further following the PatMatch [USAGE](PatMatch initial demo and introduction.ipynb#Usage) information, sequences should be processed so that the lines of sequence data are formatted to one line for handling by PatMatch. The PatMatch authors have provided a utility script for doing that preparation step. The following cell will run that on the example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../patmatch_1.2/unjustify_fasta.pl chrmt.fsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will produce a file with `.prepared` appended to the end of the supplied file name. \n",
    "\n",
    "Check that file was produced by running checking the file listing again using `!ls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having verified the prepared data file exists, you are ready to run the program to search for a pattern.\n",
    "\n",
    "### Running PatMatch\n",
    "\n",
    "The PatMatch [USAGE](PatMatch initial demo and introduction.ipynb#Usage) information says `-n` is for nucleotide pattern match and `-c` is for complementary strand; however, [based on my tests](PatMatch nucleic handling flags demystified.ipynb) it seems that `-c` means it is for the complementary strand **in addition to** the strand in the dataset. \n",
    "\n",
    "**<font color=\"red\">Therefore, if you want the pattern search to be performed on BOTH strands of the supplied sequence, as is the default of the web-based PatMatch tools, you actually want to use the `-c` flag when authoring the command.</font>**\n",
    "\n",
    "If you are curious about this aspect futher, I demonstrate that [here](PatMatch nucleic handling flags demystified.ipynb) and in the course of that cover how to replicate the three options typically offered for strand at PatMatch web-based offerings. Feel free to examine and run that notebook or simply use the `-c` flag if you are trying to scan both strands. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !perl ../patmatch_1.2/patmatch.pl -n \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared #dataset strand only\n",
    "!perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the basics of running PatMatch. There are options you can add to control this mismatch amount and whether to allow insertions,deletiions, or substitutions towards thos mismtaches. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared 1 ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [USAGE](PatMatch initial demo and introduction.ipynb#Usage) for more information about those options. However, that covers the basics.\n",
    "\n",
    "With the basics in hand, and using the power of the command line, searches of more sequences or more sequences and more patterns become possible. However, you'll quickly encounter problems handling all those results. As a simple example, we'll use the example pattern matching search we developed above as example for integrating with Python for more efficient handling of the results and to touch upon the advantanges offered by combining with a scripting language.\n",
    "\n",
    "## Importing PatMatch Results into a Pandas Dataframe and Exporting to Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you see what PatMatch is returning as results, you'll probably note that why that looks easy to read for a human, it isn't very computer friendly. Indeed, if you have used the web-based PatMatch offerings, you'll note that they return the results in a table form that is more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ways to add the data to the running Binder are available using the file directory dashboard. EXPLAIN HOW TO UPLOAD using JUPYTER GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/a/42703609/8508004\n",
    "import io\n",
    "#import pandas as pd\n",
    "output = !perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared 1 ids\n",
    "#df = pd.read_table(io.StringIO(output.n))\n",
    "print(type(output)) # see http://ipython.readthedocs.io/en/stable/api/generated/IPython.utils.text.html#IPython.utils.text.SList\n",
    "print (output.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl ../patmatch_1.2/patmatch.pl -c \"DDWDWTAWAAGTARTADDDD\" chrmt.fsa.prepared > test.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# patmatch_results_to_df.py\n",
    "__author__ = \"Wayne Decatur\" #fomightez on GitHub\n",
    "__license__ = \"MIT\"\n",
    "__version__ = \"0.1.0\"\n",
    "\n",
    "\n",
    "# patmatch_results_to_df.py by Wayne Decatur\n",
    "# ver 0.1\n",
    "#\n",
    "#*******************************************************************************\n",
    "# Verified compatible with both Python 2.7 and Python 3.6; written initially in \n",
    "# Python 3. (See below.)\n",
    "#\n",
    "#\n",
    "# PURPOSE: Takes output from command line-based PatMatch and brings it into \n",
    "# Python as a dataframe and saves a file of that dataframe for use elsewhere. \n",
    "# Optionally, it can also return that dataframe for use inside a Jupyter \n",
    "# notebook.\n",
    "#\n",
    "# This script is meant to be a utility script for working with command \n",
    "# line-based PatMatch and Python, see a demonstration of use in\n",
    "# https://github.com/fomightez/patmatch-binder/blob/master/notebooks/PatMatch%20with%20Python.ipynb\n",
    "# \n",
    "# Assumes for nucleic acid patterns, it was run with `-c` flag and tries to \n",
    "# assign strand information.\n",
    "# \n",
    "# See https://github.com/fomightez/patmatch-binder about PatMatch.\n",
    "#\n",
    "# Written to run from command line or pasted/loaded inside a Jupyter notebook \n",
    "# cell. \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# Verified compatible with both Python 2.7 and Python 3.6; written initially in \n",
    "# Python 3. \n",
    "#\n",
    "#\n",
    "# Dependencies beyond the mostly standard libraries/modules:\n",
    "#\n",
    "#\n",
    "#\n",
    "# VERSION HISTORY:\n",
    "# v.0.1. basic working version\n",
    "\n",
    "#\n",
    "# To do:\n",
    "# - verify compatible with 2.7 (use output from patmatch-binder) OTHERWISE, FIX TWO NOTES ABOVE ABOUT 2.7\n",
    "# - add way to bring in pattern searched\n",
    "# - add in way to signal nucleic or protein because with protein data won't need\n",
    "#   strand handling\n",
    "# - incorporate in demo notebook in patmatch-binder; also(?) in that demo binder \n",
    "#   show how to bring into Python theweb-based PatMatch data from the xls file?\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# TO RUN:\n",
    "# Examples,\n",
    "# Enter on the command line of your terminal, the line\n",
    "#-----------------------------------\n",
    "# python patmatch_results_to_df.py -RESULTS_FILE\n",
    "#-----------------------------------\n",
    "# Issue `patmatch_results_to_df.py -h` for details.\n",
    "# \n",
    "#\n",
    "# When using in a notebook, if you don't specify dataframe objects, , you must\n",
    "# instead supply strings of file names for the pickled dataframes in the call\n",
    "# to the main function. \n",
    "# To use this after pasting or loading into a cell in a Jupyter notebook, in\n",
    "# the next cell specify the two dataframes then call the main function similar \n",
    "# to below:\n",
    "# pattern= \"DDWDWTAWAAGTARTADDDD\"\n",
    "# df = patmatch_results_to_df(\"test.out\", pattern=pattern)\n",
    "# df\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# \n",
    "#\n",
    "'''\n",
    "CURRENT ACTUAL CODE FOR RUNNING/TESTING IN A NOTEBOOK WHEN LOADED OR PASTED IN \n",
    "ANOTHER CELL:\n",
    "pattern= \"DDWDWTAWAAGTARTADDDD\"\n",
    "df = patmatch_results_to_df(\"test.out\", pattern=pattern)\n",
    "df\n",
    "'''\n",
    "#\n",
    "#\n",
    "#*******************************************************************************\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*******************************************************************************\n",
    "##################################\n",
    "#  USER ADJUSTABLE VALUES        #\n",
    "\n",
    "##################################\n",
    "#\n",
    "\n",
    "## Settings and options for output plot \n",
    "df_save_as_name = 'patmatch_pickled_df.pkl' # name for saving pickled dataframe\n",
    "\n",
    "#\n",
    "#*******************************************************************************\n",
    "#**********************END USER ADJUSTABLE VARIABLES****************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*******************************************************************************\n",
    "#*******************************************************************************\n",
    "###DO NOT EDIT BELOW HERE - ENTER VALUES ABOVE###\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*******************************************************************************\n",
    "###------------------------'main' function of script---------------------------##\n",
    "\n",
    "def patmatch_results_to_df(\n",
    "    results_file, pattern=\"?\", return_df = True, pickle_df=True):\n",
    "    '''\n",
    "    Main function of script. \n",
    "    It will take a file of results from command line-based PatMatch and make\n",
    "    a dataframe that will be more useful with Python/othergenetic-oriented \n",
    "    scripts.\n",
    "    Optionally also returns a dataframe of the results data. Meant for use in \n",
    "    a Jupyter notebook.\n",
    "    '''\n",
    "    # Bring in the necessary data:\n",
    "    #---------------------------------------------------------------------------\n",
    "\n",
    "    with open(results_file, 'r') as the_file:\n",
    "        results = the_file.read()\n",
    "\n",
    "    # feedback\n",
    "    sys.stderr.write(\"Provided results read...\")\n",
    "\n",
    "\n",
    "    # Parse:\n",
    "    #---------------------------------------------------------------------------\n",
    "    results = results.split('>')\n",
    "    # remove blanks\n",
    "    results = [x for x in results if x]\n",
    "\n",
    "    # prepare to give some unique indentifiers to each match\n",
    "    identifiers=[]\n",
    "    if pattern == \"?\":\n",
    "        id_prefix = \"pattern-\"\n",
    "    elif len(pattern) > 29:\n",
    "        id_prefix = pattern[:25] + \"...-\"\n",
    "    else:\n",
    "        id_prefix = pattern + \"-\"\n",
    "\n",
    "    matching_patterns = []\n",
    "    starts = []\n",
    "    ends = []\n",
    "    strand_info = []\n",
    "    for indx,each in enumerate(results):\n",
    "        each_part = each.split()\n",
    "        first_line, matching_pattern = each_part[0].strip(),each_part[1].strip()\n",
    "        # Because I wanted to include `.strip()`, it seemed I couldn't do last\n",
    "        # two lines all as `first_line, matching_pattern= each.split()[:2]`\n",
    "\n",
    "        # Parse numbers between the brackets in first line(first, I will split\n",
    "        # on the ':' just in case the extracted first line has `[]` in first \n",
    "        # part)\n",
    "        second_half = first_line.split(\":\")[1]\n",
    "        nums_str = second_half[second_half.find(\"[\")+1:second_half.find(\"]\")]\n",
    "        nums = nums_str.split(\",\")[:2]\n",
    "        start,end = nums[0],nums[1]\n",
    "        # Determine strand. \n",
    "        # I noticed when `-c` flag is used the first number in the interval \n",
    "        # returned to indicate the location will be larger than the second for \n",
    "        # those on the negative strand. \n",
    "        if start > end:\n",
    "            strand = -1\n",
    "            # fix start and end so start is actually lowest value to be \n",
    "            # consistent with system I have been using of late (like Ensembl)\n",
    "            start, end = end,start\n",
    "\n",
    "        else:\n",
    "            strand = 1\n",
    "        assert start < end ,\"The 'start' value should be lower; strand \\\n",
    "        information is handled by `strand` property.\"\n",
    "        identifiers.append(id_prefix+str(indx+1)) #`+1` so numbering more \n",
    "        # tpyical than python zero-indexing\n",
    "        matching_patterns.append(matching_pattern)\n",
    "        starts.append(start)\n",
    "        ends.append(end)\n",
    "        strand_info.append(strand)\n",
    "\n",
    "    # Make collected results into dataframe and improve on it\n",
    "    #---------------------------------------------------------------------------\n",
    "    df = pd.DataFrame(list(zip(\n",
    "        identifiers, starts, ends,strand_info, matching_patterns)),\n",
    "        columns=['seq_id', 'start','end','strand','matching pattern'])\n",
    "    # add query pattern as a column\n",
    "    df['query pattern'] = pattern\n",
    "\n",
    "    # better re-order the columns(?)\n",
    "\n",
    "\n",
    "    #print(updated_sites_df)#originally for debugging during development,added..\n",
    "    # Document the full set of data collected in the terminal or \n",
    "    # Jupyter notebook display in some manner. \n",
    "    # Using `df.to_string()` because more universal than `print(df)` \n",
    "    # or Jupyter's `display(df)`.\n",
    "    sys.stderr.write( \"\\nFor documenting purposes, the following lists the \"\n",
    "        \"parsed data:\\n\")\n",
    "    #with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    #    display(df)\n",
    "    sys.stderr.write(df.to_string())\n",
    "\n",
    "    # Handle pickling the modified sites dataframe\n",
    "    if pickle_df == False:\n",
    "        sys.stderr.write(\"\\n\\nA dataframe of the parsed data shown above \"\n",
    "        \"was not stored for use\\nelsewhere \"\n",
    "        \"because `no_pickling` was specified in place of the output file name.\")\n",
    "    else:\n",
    "        df.to_pickle(df_save_as_name )\n",
    "        # Let user know\n",
    "        sys.stderr.write( \"\\n\\nA dataframe of the parsed data shown above \"\n",
    "        \"has been\\nsaved as a file in a manner where other \"\n",
    "        \"Python programs\\ncan access it (pickled form).\\n\"\n",
    "        \"RESULTING DATAFRAME is stored as ==> '{}'\".format(df_save_as_name ))\n",
    "\n",
    "    # optionally, return df\n",
    "    if return_df:\n",
    "        sys.stderr.write( \"\\n\\nReturning a dataframe with the information \"\n",
    "                \"as well.\")\n",
    "        return df\n",
    "\n",
    "###--------------------------END OF MAIN FUNCTION----------------------------###\n",
    "###--------------------------END OF MAIN FUNCTION----------------------------###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*******************************************************************************\n",
    "###------------------------'main' section of script---------------------------##\n",
    "\n",
    "def main():\n",
    "    \"\"\" Main entry point of the script \"\"\"\n",
    "    # placing actual main action in a 'helper'script so can call that easily \n",
    "    # with a distinguishing name in Jupyter notebooks, where `main()` may get\n",
    "    # assigned multiple times depending how many scripts imported/pasted in.\n",
    "    kwargs = {}\n",
    "    if args.pattern:\n",
    "        kwargs['pattern'] = args.pattern\n",
    "    else:\n",
    "        kwargs['pattern'] = '?'\n",
    "    if df_save_as_name == 'no_pickling':\n",
    "        kwargs['pickle_df'] = False\n",
    "    kwargs['return_df'] = False #probably don't want dataframe returned if \n",
    "    # calling script from command line\n",
    "    patmatch_results_to_df(results_file,**kwargs)\n",
    "    # using https://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/#calling-a-function\n",
    "    # to build keyword arguments to pass to the function above\n",
    "    # (see https://stackoverflow.com/a/28986876/8508004 and\n",
    "    # https://stackoverflow.com/a/1496355/8508004 \n",
    "    # (maybe https://stackoverflow.com/a/7437238/8508004 might help too) for \n",
    "    # related help)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" and '__file__' in globals():\n",
    "    \"\"\" This is executed when run from the command line \"\"\"\n",
    "    # Code with just `if __name__ == \"__main__\":` alone will be run if pasted\n",
    "    # into a notebook. The addition of ` and '__file__' in globals()` is based\n",
    "    # on https://stackoverflow.com/a/22923872/8508004\n",
    "    # See also https://stackoverflow.com/a/22424821/8508004 for an option to \n",
    "    # provide arguments when prototyping a full script in the notebook.\n",
    "    ###-----------------for parsing command line arguments-----------------------###\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(prog='patmatch_results_to_df.py',\n",
    "        description=\"patmatch_results_to_df.py \\\n",
    "        Takes output from command line-based PatMatch and brings it into \\\n",
    "        Python as a dataframe and saves a file of that dataframe for use \\\n",
    "        elsewhere. Optionally, it can also return that dataframe for use \\\n",
    "        inside a Jupyter notebook. Meant to be a utility script for working \\\n",
    "        with command line-based PatMatch and Python.\\\n",
    "        Assumes for nucleic acid patterns, it was run with `-c` flag and tries \\\n",
    "        to assign strand. \\\n",
    "        **** Script by Wayne Decatur   \\\n",
    "        (fomightez @ github) ***\")\n",
    "\n",
    "    parser.add_argument(\"results_file\", help=\"Name of file of PatMatch results \\\n",
    "        file to parse.\\\n",
    "        \", metavar=\"RESULTS_FILE\")\n",
    "    parser.add_argument('-patt', '--pattern', action='store', type=str, \n",
    "        help=\"**OPTIONAL** Pattern used to perform the pattern matching search \\\n",
    "        that generated the results. The resulting dataframe will more \\\n",
    "        informative if one is provided; however, it is not essential. To \\\n",
    "        provide the pattern simply enter the text after the flag. For example, \\\n",
    "        if the search had been for an EcoRI site, include `--pattern GAATTC`, \\\n",
    "        without quotes or ticks, in the call to the script.\")\n",
    "    parser.add_argument(\"-p\", \"--protein_results\",help=\n",
    "    \"add this flag to indicate the data are from a pattern match of protein \\\n",
    "    sequences. Otherwise it assumed the results are from pattern matching on \\\n",
    "    nucleic acid sequences.\", action=\"store_true\")\n",
    "    parser.add_argument('-dfo', '--df_output', action='store', type=str, \n",
    "    default= df_save_as_name, help=\"OPTIONAL: Set file name for saving pickled \\\n",
    "    dataframe. If none provided, '{}' will be used. To force no dataframe to \\\n",
    "    be saved, enter `-dfo no_pickling` without quotes as output file \\\n",
    "    (ATYPICAL).\".format(df_save_as_name))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #I would also like trigger help to display if no arguments provided because \n",
    "    # need at least one for url\n",
    "    if len(sys.argv)==1:    #from http://stackoverflow.com/questions/4042452/display-help-message-with-python-argparse-when-script-is-called-without-any-argu\n",
    "        parser.print_help()\n",
    "        sys.exit(1)\n",
    "    args = parser.parse_args()\n",
    "    results_file= args.results_file\n",
    "    df_save_as_name = args.df_output\n",
    "\n",
    "\n",
    "    main()\n",
    "\n",
    "#*******************************************************************************\n",
    "###-***********************END MAIN PORTION OF SCRIPT***********************-###\n",
    "#*******************************************************************************\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern= \"DDWDWTAWAAGTARTADDDD\"\n",
    "df = patmatch_results_to_df(\"test.out\", pattern=pattern)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://gist.githubusercontent.com/fomightez/b012e51ebef6ec58c1515df3ee0c850a/raw/300da6c67ceeaf5384a3e500648b993345c361cb/run_every_eight_mins.py\n",
    "import time\n",
    "\n",
    "def executeSomething():\n",
    "    #code here\n",
    "    print ('.')\n",
    "    time.sleep(480) #60 seconds times 8 minutes\n",
    "\n",
    "while True:\n",
    "    executeSomething()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
